{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оптимизация методов бинарной классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fields: `Amount` и `Value`\n",
    "- Robust Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn    = pd.read_csv('../data/training_le.csv')\n",
    "df_tst    = pd.read_csv('../data/test_le.csv')\n",
    "df_sbm    = pd.read_csv('../data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BatchId</th>\n",
       "      <th>AccountId</th>\n",
       "      <th>SubscriptionId</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>ProviderId</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>ProductCategory</th>\n",
       "      <th>ChannelId</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Value</th>\n",
       "      <th>TransactionStartTime</th>\n",
       "      <th>PricingStrategy</th>\n",
       "      <th>FraudResult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36122</td>\n",
       "      <td>3956</td>\n",
       "      <td>886</td>\n",
       "      <td>4405</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>2018-11-15 02:18:49</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15641</td>\n",
       "      <td>4840</td>\n",
       "      <td>3828</td>\n",
       "      <td>4405</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>20</td>\n",
       "      <td>2018-11-15 02:19:08</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53940</td>\n",
       "      <td>4228</td>\n",
       "      <td>221</td>\n",
       "      <td>4682</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500</td>\n",
       "      <td>2018-11-15 02:44:21</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102362</td>\n",
       "      <td>647</td>\n",
       "      <td>2184</td>\n",
       "      <td>987</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>21800</td>\n",
       "      <td>2018-11-15 03:32:55</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38779</td>\n",
       "      <td>4840</td>\n",
       "      <td>3828</td>\n",
       "      <td>987</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-644.0</td>\n",
       "      <td>644</td>\n",
       "      <td>2018-11-15 03:34:21</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BatchId  AccountId  SubscriptionId  CustomerId  ProviderId  ProductId  \\\n",
       "0    36122       3956             886        4405           5          9   \n",
       "1    15641       4840            3828        4405           3          5   \n",
       "2    53940       4228             221        4682           5          0   \n",
       "3   102362        647            2184         987           0         20   \n",
       "4    38779       4840            3828         987           3          5   \n",
       "\n",
       "   ProductCategory  ChannelId   Amount  Value TransactionStartTime  \\\n",
       "0                0          2   1000.0   1000  2018-11-15 02:18:49   \n",
       "1                2          1    -20.0     20  2018-11-15 02:19:08   \n",
       "2                0          2    500.0    500  2018-11-15 02:44:21   \n",
       "3                9          2  20000.0  21800  2018-11-15 03:32:55   \n",
       "4                2          1   -644.0    644  2018-11-15 03:34:21   \n",
       "\n",
       "   PricingStrategy  FraudResult  \n",
       "0                2            0  \n",
       "1                2            0  \n",
       "2                2            0  \n",
       "3                2            0  \n",
       "4                2            0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BatchId',\n",
       " 'AccountId',\n",
       " 'SubscriptionId',\n",
       " 'CustomerId',\n",
       " 'ProviderId',\n",
       " 'ProductId',\n",
       " 'ProductCategory',\n",
       " 'ChannelId',\n",
       " 'Amount',\n",
       " 'Value',\n",
       " 'TransactionStartTime',\n",
       " 'PricingStrategy',\n",
       " 'FraudResult']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_trn.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns4drop = [\n",
    "    'BatchId', \n",
    "    'AccountId', \n",
    "    'SubscriptionId', \n",
    "    'CustomerId', \n",
    "    'ProviderId',\n",
    "    'ProductId',\n",
    "    'ProductCategory',\n",
    "    'ChannelId',\n",
    "    'TransactionStartTime',\n",
    "    'PricingStrategy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn = df_trn.drop(columns4drop, axis=1)\n",
    "df_tst = df_tst.drop(columns4drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleColumns(data, cols_to_scale, scaler):\n",
    "    for col in cols_to_scale:\n",
    "        data[col] = pd.DataFrame(scaler.fit_transform(pd.DataFrame(data[col])))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn = scaleColumns(df_trn, ['Amount', 'Value'], RobustScaler())\n",
    "df_tst = scaleColumns(df_tst, ['Amount', 'Value'], RobustScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amount</th>\n",
       "      <th>Value</th>\n",
       "      <th>FraudResult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.357895</td>\n",
       "      <td>-0.207407</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.175439</td>\n",
       "      <td>-0.105820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.666667</td>\n",
       "      <td>4.402116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.576842</td>\n",
       "      <td>-0.075344</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Amount     Value  FraudResult\n",
       "0  0.000000  0.000000            0\n",
       "1 -0.357895 -0.207407            0\n",
       "2 -0.175439 -0.105820            0\n",
       "3  6.666667  4.402116            0\n",
       "4 -0.576842 -0.075344            0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_trn.drop('FraudResult', axis=1)\n",
    "y = df_trn['FraudResult']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=24, shuffle=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Label Distribution: Counter({0: 76380, 1: 149})\n",
      "Test  Label Distribution: Counter({0: 19089, 1: 44})\n"
     ]
    }
   ],
   "source": [
    "print('Train Label Distribution: {}'.format(Counter(y_train)))\n",
    "print('Test  Label Distribution: {}'.format(Counter(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier Libraries\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "# explicitly require this experimental feature\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
    "# now you can import normally from ensemble\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'Naive Bayes                       ': GaussianNB(),\n",
    "    'k-Nearest Neighbors               ': KNeighborsClassifier(3),\n",
    "    'Decision Tree Classifier          ': DecisionTreeClassifier(max_depth=5),\n",
    "    'Logisitic Regression              ': LogisticRegression(),\n",
    "    'AdaBoost Classifier               ': AdaBoostClassifier(),\n",
    "    'Bagging Classifier                ': BaggingClassifier(),\n",
    "    'Extra-Trees Classifier            ': ExtraTreesClassifier(),\n",
    "    'Gradient Boosting                 ': GradientBoostingClassifier(),\n",
    "    'Random Forest                     ': RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    'Histogram-based GradBoostClassTree': HistGradientBoostingClassifier(),\n",
    "    'Linear Discriminant Analysis      ': LinearDiscriminantAnalysis(),\n",
    "    'Quadratic Discriminant Analysis   ': QuadraticDiscriminantAnalysis(),\n",
    "    'Multilayer Perceptron             ': MLPClassifier(alpha=1, max_iter=1000)\n",
    "}\n",
    "#     'Voting Classifier              ': VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='soft'),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier =  KNeighborsClassifier(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cross_validate(classifier, X_train.values, y_train.values, scoring=('precision', 'recall', 'f1'), cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-Nearest Neighbors 0.92856  \t 0.78414  \t 0.84204  \t 1.54\n"
     ]
    }
   ],
   "source": [
    "name = 'k-Nearest Neighbors'\n",
    "print(name,\n",
    "          round(cv_results['test_precision'].mean(), 5), ' \\t',\n",
    "          round(cv_results['test_recall'].mean(),    5), ' \\t',\n",
    "          round(cv_results['test_f1'].mean(),        5), ' \\t',\n",
    "          round(cv_results['fit_time'].sum(),        2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hpsklearn import HyperoptEstimator, knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "estim = HyperoptEstimator(classifier=knn('myKNN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.18s/it, best loss: 0.0015680125441003279]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.38it/s, best loss: 0.0007840062720502194]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.98s/it, best loss: 0.000653338560041794]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.42it/s, best loss: 0.000653338560041794]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.20s/it, best loss: 0.000653338560041794]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.21s/it, best loss: 0.000653338560041794]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.41it/s, best loss: 0.000653338560041794]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.58it/s, best loss: 0.000653338560041794]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.23it/s, best loss: 0.000653338560041794]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.42it/s, best loss: 0.000653338560041794]\n"
     ]
    }
   ],
   "source": [
    "estim.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = estim.predict(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6582278481012659"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test.values, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary of all values we want to test for n_neighbors\n",
    "knn_GS_params = {\n",
    "    'n_neighbors': np.arange(1, 25),\n",
    "    'weights'    : ['uniform', 'distance'],\n",
    "    'metric'     : ['euclidean', 'manhattan', 'minkowski']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use gridsearch to test all values for n_neighbors\n",
    "knn_gs = GridSearchCV(KNeighborsClassifier(), knn_GS_params, verbose=1, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done 188 tasks      | elapsed:   23.7s\n",
      "[Parallel(n_jobs=-1)]: Done 438 tasks      | elapsed:   59.4s\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed:  1.6min finished\n"
     ]
    }
   ],
   "source": [
    "#fit model to data\n",
    "knn_gs_results = knn_gs.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9995165231480877"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_gs_results.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=15, p=2,\n",
       "                     weights='distance')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_gs_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': 'euclidean', 'n_neighbors': 15, 'weights': 'distance'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_gs_results.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_opt = knn_gs_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = knn_opt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9268292682926829"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_3 = KNeighborsClassifier(3).fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = knn_3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9318181818181818"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hpsklearn import HyperoptEstimator, svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estim = HyperoptEstimator(classifier=svc('mySVC'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estim.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over classifiers\n",
    "print('Classifiers \\t\\t\\t Precision \\t Recall \\t F1-score \\t Fit-time')\n",
    "for name, classifier in classifiers.items():\n",
    "    classifier.fit(X_train, y_train)\n",
    "    cv_results = cross_validate(classifier, X_train.values, y_train.values, scoring=('precision', 'recall', 'f1'), cv=5, n_jobs=-1)\n",
    "    print(name,\n",
    "          round(cv_results['test_precision'].mean(), 5), ' \\t',\n",
    "          round(cv_results['test_recall'].mean(),    5), ' \\t',\n",
    "          round(cv_results['test_f1'].mean(),        5), ' \\t',\n",
    "          round(cv_results['fit_time'].sum(),        2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over classifiers\n",
    "print('Classifiers \\t\\t\\t Precision \\t Recall \\t F1-score \\t Fit-time')\n",
    "for name, classifier in classifiers.items():\n",
    "    classifier.fit(X_train, y_train)\n",
    "    cv_results = cross_validate(classifier, X_train, y_train,\n",
    "                                scoring=('precision', 'recall', 'f1'), cv=5, n_jobs=-1)\n",
    "\n",
    "    print(name,\n",
    "          round(cv_results['test_precision'].mean(), 4), ' \\t',\n",
    "          round(cv_results['test_recall'].mean(),    4), ' \\t',\n",
    "          round(cv_results['test_f1'].mean(),        4), ' \\t',\n",
    "          round(cv_results['fit_time'].sum(),        2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Precision = \\frac{TP}{TP+FP}$\n",
    "\n",
    "$Recall = \\frac{TP}{TP+FN}$\n",
    "\n",
    "$F1 = 2\\cdot\\frac{Precision\\cdot{Recall}}{Precision+Recall}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over classifiers\n",
    "print('Classifiers \\t\\t\\t     TN     FP    FN    TP   Precision    Recall     F1-score')\n",
    "print('-' * 95)\n",
    "for name, classifier in classifiers.items():\n",
    "    classifier.fit(X_train, y_train)\n",
    "    predict = classifier.predict(X_test)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, predict).ravel()\n",
    "    precision      = precision_score(y_test, predict)\n",
    "    recall         = recall_score(y_test, predict)\n",
    "    f1             = f1_score(y_test, predict)\n",
    "\n",
    "    print('%s %5i %5i %5i %5i %10.4f %10.4f %10.4f' % (name, tn, fp, fn, tp, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tst.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "#     'Naive Bayes                       ': GaussianNB(),\n",
    "    'k-Nearest Neighbors               ': KNeighborsClassifier(3),\n",
    "    'Decision Tree Classifier          ': DecisionTreeClassifier(max_depth=5),\n",
    "    'Logisitic Regression              ': LogisticRegression(),\n",
    "    'AdaBoost Classifier               ': AdaBoostClassifier(),\n",
    "    'Bagging Classifier                ': BaggingClassifier(),\n",
    "    'Extra-Trees Classifier            ': ExtraTreesClassifier(),\n",
    "    'Gradient Boosting                 ': GradientBoostingClassifier(),\n",
    "    'Random Forest                     ': RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "#     'Histogram-based GradBoostClassTree': HistGradientBoostingClassifier(),\n",
    "    'Linear Discriminant Analysis      ': LinearDiscriminantAnalysis(),\n",
    "#     'Quadratic Discriminant Analysis   ': QuadraticDiscriminantAnalysis(),\n",
    "    'Multilayer Perceptron             ': MLPClassifier(alpha=1, max_iter=1000)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, classifier in classifiers.items():\n",
    "    classifier.fit(X, y)\n",
    "    predict = classifier.predict(df_tst)\n",
    "\n",
    "    print(name, ':', Counter(predict))\n",
    "    df_sbm['FraudResult'] = predict\n",
    "    df_sbm.to_csv('../submitted/AlBo0713_' + name.rstrip().replace(' ', '_') + '.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results on ZINDI\n",
    "- 'k-Nearest Neighbors               ': 0.549019607843137\n",
    "- 'Decision Tree Classifier          ': 0.583333333333333\n",
    "- 'Logisitic Regression              ': 0.528301886792453\n",
    "- 'AdaBoost Classifier               ': 0.6\n",
    "- 'Bagging Classifier                ': 0.688524590163934\n",
    "- 'Extra-Trees Classifier            ': 0.592592592592593\n",
    "- 'Gradient Boosting                 ': 0.4\n",
    "- 'Random Forest                     ': 0.694444444444444 === 1-st place ===\n",
    "- 'Linear Discriminant Analysis      ': 0.555555555555556\n",
    "- 'Multilayer Perceptron             ': 0.512820512820513"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_sc = {\n",
    "    'Support Vector Classifier, Linear': SVC(kernel=\"linear\", C=0.025),\n",
    "    'Support Vector Classifier, RBF   ': SVC(kernel=\"rbf\", gamma=2, C=1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over classifiers_sc\n",
    "print('Classifiers \\t\\t Cross_val_score \\t Time')\n",
    "for name, classifier in classifiers_sc.items():\n",
    "    tac = time()\n",
    "    classifier.fit(X_sc_train, y_sc_train)\n",
    "    training_score = cross_val_score(classifier, X_sc_train, y_sc_train, cv=5)\n",
    "    tic = time()\n",
    "    print(name, round(training_score.mean(), 5), ' \\t', round(tic-tac, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 0]\n",
    "def fp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 1]\n",
    "def fn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 0]\n",
    "def tp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 1]\n",
    "scoring = {'tp': make_scorer(tp),\n",
    "           'tn': make_scorer(tn),\n",
    "           'fp': make_scorer(fp),\n",
    "           'fn': make_scorer(fn)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cross_validate(svm.fit(X, y), X, y, scoring=scoring, cv=5)\n",
    "# Getting the test set true positive scores\n",
    "print(cv_results['test_tp'])  \n",
    "\n",
    "# Getting the test set false negative scores\n",
    "print(cv_results['test_fn'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will undersample during cross validating\n",
    "undersample_X = df.drop('Class', axis=1)\n",
    "undersample_y = df['Class']\n",
    "\n",
    "for train_index, test_index in sss.split(undersample_X, undersample_y):\n",
    "    print(\"Train:\", train_index, \"Test:\", test_index)\n",
    "    undersample_Xtrain, undersample_Xtest = undersample_X.iloc[train_index], undersample_X.iloc[test_index]\n",
    "    undersample_ytrain, undersample_ytest = undersample_y.iloc[train_index], undersample_y.iloc[test_index]\n",
    "    \n",
    "undersample_Xtrain = undersample_Xtrain.values\n",
    "undersample_Xtest = undersample_Xtest.values\n",
    "undersample_ytrain = undersample_ytrain.values\n",
    "undersample_ytest = undersample_ytest.values \n",
    "\n",
    "undersample_accuracy = []\n",
    "undersample_precision = []\n",
    "undersample_recall = []\n",
    "undersample_f1 = []\n",
    "undersample_auc = []\n",
    "\n",
    "# Implementing NearMiss Technique \n",
    "# Distribution of NearMiss (Just to see how it distributes the labels we won't use these variables)\n",
    "X_nearmiss, y_nearmiss = NearMiss().fit_sample(undersample_X.values, undersample_y.values)\n",
    "print('NearMiss Label Distribution: {}'.format(Counter(y_nearmiss)))\n",
    "# Cross Validating the right way\n",
    "\n",
    "for train, test in sss.split(undersample_Xtrain, undersample_ytrain):\n",
    "    undersample_pipeline = imbalanced_make_pipeline(NearMiss(sampling_strategy='majority'), log_reg) # SMOTE happens during Cross Validation not before..\n",
    "    undersample_model = undersample_pipeline.fit(undersample_Xtrain[train], undersample_ytrain[train])\n",
    "    undersample_prediction = undersample_model.predict(undersample_Xtrain[test])\n",
    "    \n",
    "    undersample_accuracy.append(undersample_pipeline.score(original_Xtrain[test], original_ytrain[test]))\n",
    "    undersample_precision.append(precision_score(original_ytrain[test], undersample_prediction))\n",
    "    undersample_recall.append(recall_score(original_ytrain[test], undersample_prediction))\n",
    "    undersample_f1.append(f1_score(original_ytrain[test], undersample_prediction))\n",
    "    undersample_auc.append(roc_auc_score(original_ytrain[test], undersample_prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
