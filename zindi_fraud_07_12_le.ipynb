{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выбор метода бинарной классификации на полях `Amount` и `Value`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn    = pd.read_csv('../data/training_le.csv')\n",
    "df_tst    = pd.read_csv('../data/test_le.csv')\n",
    "df_sbm    = pd.read_csv('../data/sample_submission.csv')\n",
    "\n",
    "df_trn_sc = pd.read_csv('../data/training_le.csv')\n",
    "df_tst_sc = pd.read_csv('../data/test_le.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BatchId', 'AccountId', 'SubscriptionId', 'CustomerId', 'ProviderId',\n",
       "       'ProductId', 'ProductCategory', 'ChannelId', 'Amount', 'Value',\n",
       "       'TransactionStartTime', 'PricingStrategy', 'FraudResult'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trn.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns4drop = [\n",
    "    'BatchId', \n",
    "    'AccountId', \n",
    "    'SubscriptionId', \n",
    "    'CustomerId', \n",
    "    'ProviderId',\n",
    "    'ProductId',\n",
    "    'ProductCategory',\n",
    "    'ChannelId',\n",
    "    'TransactionStartTime',\n",
    "    'PricingStrategy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn    = df_trn.drop(columns4drop, axis=1)\n",
    "df_tst    = df_tst.drop(columns4drop, axis=1)\n",
    "\n",
    "df_trn_sc = df_trn_sc.drop(columns4drop, axis=1)\n",
    "df_tst_sc = df_tst_sc.drop(columns4drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PowerTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns4MinMaxScaler = [\n",
    "    'BatchId',\n",
    "    'AccountId', \n",
    "    'SubscriptionId', \n",
    "    'CustomerId', \n",
    "    'ProviderId',\n",
    "    'ProductId', \n",
    "    'ProductCategory', \n",
    "    'ChannelId',\n",
    "    'PricingStrategy'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# int --> float\n",
    "for clm in columns4MinMaxScaler:\n",
    "    df_trn_sc[clm] = df_trn_sc[clm].astype(float)\n",
    "    df_tst_sc[clm] = df_tst_sc[clm].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleColumns(data, cols_to_scale, scaler):\n",
    "    for col in cols_to_scale:\n",
    "        data[col] = pd.DataFrame(scaler.fit_transform(pd.DataFrame(data[col])))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn_sc = scaleColumns(df_trn_sc, columns4MinMaxScaler, MinMaxScaler())\n",
    "df_tst_sc = scaleColumns(df_tst_sc, columns4MinMaxScaler, MinMaxScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn_sc = scaleColumns(df_trn_sc, ['Amount', 'Value'], RobustScaler())\n",
    "df_tst_sc = scaleColumns(df_tst_sc, ['Amount', 'Value'], RobustScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amount</th>\n",
       "      <th>Value</th>\n",
       "      <th>FraudResult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-20.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500.0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>21800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-644.0</td>\n",
       "      <td>644</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Amount  Value  FraudResult\n",
       "0   1000.0   1000            0\n",
       "1    -20.0     20            0\n",
       "2    500.0    500            0\n",
       "3  20000.0  21800            0\n",
       "4   -644.0    644            0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amount</th>\n",
       "      <th>Value</th>\n",
       "      <th>FraudResult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.357895</td>\n",
       "      <td>-0.207407</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.175439</td>\n",
       "      <td>-0.105820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.666667</td>\n",
       "      <td>4.402116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.576842</td>\n",
       "      <td>-0.075344</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Amount     Value  FraudResult\n",
       "0  0.000000  0.000000            0\n",
       "1 -0.357895 -0.207407            0\n",
       "2 -0.175439 -0.105820            0\n",
       "3  6.666667  4.402116            0\n",
       "4 -0.576842 -0.075344            0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trn_sc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X    = df_trn.drop('FraudResult', axis=1)\n",
    "y    = df_trn['FraudResult']\n",
    "\n",
    "X_sc = df_trn_sc.drop('FraudResult', axis=1)\n",
    "y_sc = df_trn_sc['FraudResult']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is explicitly used for undersampling\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=24)\n",
    "\n",
    "X_sc_train, X_sc_test, y_sc_train, y_sc_test = train_test_split(X_sc, y_sc, test_size=0.2, random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the values into an array for feeding the classification algorithms.\n",
    "X_train = X_train.values\n",
    "X_test  = X_test.values\n",
    "y_train = y_train.values\n",
    "y_test  = y_test.values\n",
    "\n",
    "X_sc_train = X_sc_train.values\n",
    "X_sc_test  = X_sc_test.values\n",
    "y_sc_train = y_sc_train.values\n",
    "y_sc_test  = y_sc_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Label Distribution: Counter({0: 76380, 1: 149})\n",
      "Train-Scaled Label Distribution: Counter({0: 76380, 1: 149})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print('Train Label Distribution: {}'.format(Counter(y_train)))\n",
    "print('Train-Scaled Label Distribution: {}'.format(Counter(y_sc_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier Libraries\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "# explicitly require this experimental feature\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
    "# now you can import normally from ensemble\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'Naive Bayes                       ': GaussianNB(),\n",
    "    'k-Nearest Neighbors               ': KNeighborsClassifier(3),\n",
    "    'Decision Tree Classifier          ': DecisionTreeClassifier(max_depth=5),\n",
    "    'Logisitic Regression              ': LogisticRegression(),\n",
    "    'AdaBoost Classifier               ': AdaBoostClassifier(),\n",
    "    'Bagging Classifier                ': BaggingClassifier(),\n",
    "    'Extra-Trees Classifier            ': ExtraTreesClassifier(),\n",
    "    'Gradient Boosting                 ': GradientBoostingClassifier(),\n",
    "    'Random Forest                     ': RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    'Histogram-based GradBoostClassTree': HistGradientBoostingClassifier(),\n",
    "    'Linear Discriminant Analysis      ': LinearDiscriminantAnalysis(),\n",
    "    'Quadratic Discriminant Analysis   ': QuadraticDiscriminantAnalysis(),\n",
    "    'Multilayer Perceptron             ': MLPClassifier(alpha=1, max_iter=1000)\n",
    "}\n",
    "#     'Voting Classifier              ': VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='soft'),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over classifiers\n",
    "print('Classifiers \\t\\t Cross_val_score \\t F1-score \\t Time')\n",
    "for name, classifier in classifiers.items():\n",
    "    f1 = []\n",
    "    tac = time()\n",
    "    classifier.fit(X_train, y_train)\n",
    "#     training_score = cross_val_score(classifier, X_train, y_train, cv=5)\n",
    "    \n",
    "    predict = classifier.predict(X_test)\n",
    "    f1.append(f1_score(y_test, predict))\n",
    "    tic = time()\n",
    "    print(name, round(training_score.mean(), 5), ' \\t', round(np.mean(f1), 5), '\\t', round(tic-tac, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)\n",
    "print(cross_val_score(rf, X_train, y_train, cv=5))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_sc = {\n",
    "    'Support Vector Classifier, Linear': SVC(kernel=\"linear\", C=0.025),\n",
    "    'Support Vector Classifier, RBF   ': SVC(kernel=\"rbf\", gamma=2, C=1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over classifiers_sc\n",
    "print('Classifiers \\t\\t Cross_val_score \\t Time')\n",
    "for name, classifier in classifiers_sc.items():\n",
    "    tac = time()\n",
    "    classifier.fit(X_sc_train, y_sc_train)\n",
    "    training_score = cross_val_score(classifier, X_sc_train, y_sc_train, cv=5)\n",
    "    tic = time()\n",
    "    print(name, round(training_score.mean(), 5), ' \\t', round(tic-tac, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission - AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = AdaBoostClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "predict = classifier.predict(X_test)\n",
    "print(f1_score(y_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FraudPred_AB = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FraudPred_AB = [ 1 if x == -1 else 0 for x in FraudPred_AB ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sbm['FraudResult'] = FraudPred_AB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test Label Distribution: {}'.format(Counter(df_sbm['FraudResult'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sbm.to_csv('../submitted/AlBo_07_11_AdaBoost.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission - Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier(max_depth=5)\n",
    "classifier.fit(X_train, y_train)\n",
    "predict = classifier.predict(X_test)\n",
    "print(f1_score(y_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_tst.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FraudPred_AB = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FraudPred_AB = [ 1 if x == -1 else 0 for x in FraudPred_AB ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sbm['FraudResult'] = FraudPred_AB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test Label Distribution: {}'.format(Counter(df_sbm['FraudResult'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sbm.to_csv('../submitted/AlBo_07_11_AdaBoost.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undersample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will undersample during cross validating\n",
    "undersample_X = df.drop('Class', axis=1)\n",
    "undersample_y = df['Class']\n",
    "\n",
    "for train_index, test_index in sss.split(undersample_X, undersample_y):\n",
    "    print(\"Train:\", train_index, \"Test:\", test_index)\n",
    "    undersample_Xtrain, undersample_Xtest = undersample_X.iloc[train_index], undersample_X.iloc[test_index]\n",
    "    undersample_ytrain, undersample_ytest = undersample_y.iloc[train_index], undersample_y.iloc[test_index]\n",
    "    \n",
    "undersample_Xtrain = undersample_Xtrain.values\n",
    "undersample_Xtest = undersample_Xtest.values\n",
    "undersample_ytrain = undersample_ytrain.values\n",
    "undersample_ytest = undersample_ytest.values \n",
    "\n",
    "undersample_accuracy = []\n",
    "undersample_precision = []\n",
    "undersample_recall = []\n",
    "undersample_f1 = []\n",
    "undersample_auc = []\n",
    "\n",
    "# Implementing NearMiss Technique \n",
    "# Distribution of NearMiss (Just to see how it distributes the labels we won't use these variables)\n",
    "X_nearmiss, y_nearmiss = NearMiss().fit_sample(undersample_X.values, undersample_y.values)\n",
    "print('NearMiss Label Distribution: {}'.format(Counter(y_nearmiss)))\n",
    "# Cross Validating the right way\n",
    "\n",
    "for train, test in sss.split(undersample_Xtrain, undersample_ytrain):\n",
    "    undersample_pipeline = imbalanced_make_pipeline(NearMiss(sampling_strategy='majority'), log_reg) # SMOTE happens during Cross Validation not before..\n",
    "    undersample_model = undersample_pipeline.fit(undersample_Xtrain[train], undersample_ytrain[train])\n",
    "    undersample_prediction = undersample_model.predict(undersample_Xtrain[test])\n",
    "    \n",
    "    undersample_accuracy.append(undersample_pipeline.score(original_Xtrain[test], original_ytrain[test]))\n",
    "    undersample_precision.append(precision_score(original_ytrain[test], undersample_prediction))\n",
    "    undersample_recall.append(recall_score(original_ytrain[test], undersample_prediction))\n",
    "    undersample_f1.append(f1_score(original_ytrain[test], undersample_prediction))\n",
    "    undersample_auc.append(roc_auc_score(original_ytrain[test], undersample_prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
